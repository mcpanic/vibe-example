# Daily Note 2025-12-23



## ðŸŽ¯ Feynman Hits
### Match: Project 4: A task-centric theory of AI impact on human skill development
> **Mechanism**: The concept of 'System 0' provides a precise psychological mechanism for modeling skill atrophy: AI acts as an external pre-processing layer that shapes inputs for human cognition, creating specific risks of 'epistemic dependency' where the human verification loop degrades.

ðŸ‘‰ **Action:** In your taxonomy, classify AI tasks as 'System 0' inputs. Define 'skill atrophy' specifically as the degradation of the interface between the AI's System 0 output and the human's System 2 (slow thinking) verification, rather than just the loss of the ability to execute the raw task.
ðŸ”— [Fendi Tsim's Post (referencing 'The case for humanâ€“AI interaction as system 0 thinking')](https://www.linkedin.com/posts/fenditsim_artificialintelligence-humanaiinteraction-activity-7406573844565610496-X9-Y?utm_source=share&utm_medium=member_ios&rcm=ACoAAAC5y9ABomneYkfoAYdBihF6buZNF_B9bps)

---
### Match: Project 4: A task-centric theory of AI impact on human skill development
> **Mechanism**: The guide provides a ready-made taxonomy that distinguishes 'Agentic' tasks (requiring nuanced judgment, managing unwieldy rules, interpreting unstructured data) from 'Deterministic' tasks; this distinction provides the exact boundary line needed to predict where human skill will be 'reconfigured' (Agentic) versus 'atrophied' (Deterministic).

ðŸ‘‰ **Action:** Adopt the guide's three criteria (Complex Decision Making, Rule Maintenance, Unstructured Data) as the foundational axes of your theory. Use them to categorize tasks in your telemetry data: tasks fitting these criteria should be monitored for 'skill reconfiguration' (handoffs/judgement), while tasks failing these criteria should be monitored for 'skill atrophy' (total offloading).
ðŸ”— [A Practical Guide To Building Agents](https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf)

---
